
<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">
    <link rel="stylesheet" type="text/css" href="/stylesheets/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="/stylesheets/bootstrap-theme.css" />
    <link rel="stylesheet" type="text/css" href="/stylesheets/custom.css" />
    <!-- <link rel="stylesheet" type="text/css" href="/stylesheetsassets/lesson.css" /> -->



    <title>The 5th Asian Workshop on Reinforcement Learning</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>The 5th Asian Workshop on <br> Reinforcement Learning</h1>
        <h2>AWRL'20  2020</h2>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">

<ul>
  <li><a href="#intro">Scope and Background</a></li>
  <li><a href="#schedule">Invited Speakers</a></li>
  <li><a href="#organizer">Workshop Chairs</a></li>
  <li><a href="#timetable">Overall Program</a></li>
  <li><a href="#sponsor">Contact Person</a></li>
  <!--<li><a href="#acknowledgments">Acknowledgments</a></li>-->
</ul>
<h2 id ="intro">Scope and Background</h2>

<p>
  Reinforcement learning (RL) is an active field of research that deals with the problem of (single or multiple agents') sequential decision-making in unknown and possibly partially observable domains, whose dynamics may be deterministic, stochastic or adversarial. In the last few years, we have seen a growing interest in RL from both research communities and industries, and recent developments in exploration-exploitation, credit assignment, policy search, model learning, transfer/hierarchical/interactive learning, online/multi-task learning, planning, and representation learning are making RL more and more appealing to real-world applications, with promising results in challenging domains such as recommendation systems, computer games, financial marketing, intelligent transportation systems, healthcare and robotic control. 
  After great sucesses in the past four AWRL workshops held in Hamilton, New Zealand (2016), Seoul, Korea (2017), Beijing, China (2018, 2019), the 5th AWRL workshop focuses on both theoretical models, frameworks, algorithms and analysis of RL, as well as its practical applications in various real-life domains. The half-day workshop consists of sessions devoted to invited talks on specific topics on RL and presentations on publications in top conferences such as AAMAS, AAAI, IJCAI, KDD, ICML, NeurIPS. The ultimate goal is to bring together diverse viewpoints in the RL area in an attempt to consolidate the common ground, identify new research directions, and promote the rapid advance of RL research community.
</p>

<hr/>

<!--TODO : this schedule will need to change to more accurately reflect what we are teaching -->
<h2 id="schedule">Invited Speakers</h2>
<div id="wrapper">
      <div class="figure1">
          <figure class="thumbnail">
              <a href="http://www.jilsa.net/xinxu.html"><img src="img/xuxin5.jpg" class="img-responsive" alt="Image"  height="200"></a>
              <figcaption class="caption text-center">
                <a href="http://www.jilsa.net/xinxu.html"><p><strong>徐昕</a></strong><br>
                      <small>国防科技大学</small>
                </p>
              </figcaption>
          </figure>
      </div>
      <!-- figure1 --> 
      <div class="figure1">
          <figure class="thumbnail">
              <a href="http://school.freekaoyan.com/bj/gscas/daoshi/2016/05-10/1462854999590425.shtml"><img src="img/dongbinzhao.jpg" class="img-responsive" alt="Image"  height="200"></a>
              <figcaption class="caption text-center">
                <a href="http://school.freekaoyan.com/bj/gscas/daoshi/2016/05-10/1462854999590425.shtml"><p><strong>赵东斌</a></strong><br>
                      <small>中国科学院</small>
                </p>
              </figcaption>
          </figure>
      </div>
      <!-- figure1 --> 
      <div class="figure2">
          <figure class="thumbnail">
              <img src="img/zhaoli.jpg" class="img-responsive" alt="Image"  height="200"></a>
              <figcaption class="caption text-center">
                <p><strong>赵丽</a></strong><br>
                      <small>微软亚洲研究院</small>
                </p>
              </figcaption>
          </figure>
      </div>
      <!-- figure2 --> 
</div>
<!-- /.container -->

</p>

<div id="wrapper">
      <div class="figure3">
          <figure class="thumbnail">
              <a href="https://ai.nankai.edu.cn/info/1035/3581.htm"><img src="img/xianguo.jpg" class="img-responsive" alt="Image"  height="200"></a>
              <figcaption class="caption text-center">
                <a href="https://ai.nankai.edu.cn/info/1035/3581.htm"><p><strong>郭宪</a></strong><br>
                      <small>南开大学</small>
                </p>
              </figcaption>
          </figure>
      </div>
      <!-- figure3 --> 
      <div class="figure4">
          <figure class="thumbnail">
              <a href="http://www.nlpr.ia.ac.cn/users/zhangjunge/index.htm"><img src="img/jungezhang.jpg" class="img-responsive" alt="Image"  height="200"></a>
              <figcaption class="caption text-center">
                <a href="http://www.nlpr.ia.ac.cn/users/zhangjunge/index.htm"><p><strong>张俊格</a></strong><br>
                      <small>中国科学院</small>
                </p>
              </figcaption>
          </figure>
      </div>
      <!-- figure4 --> 
      <div class="figure5">
          <figure class="thumbnail">
              <a href="http://staff.ustc.edu.cn/~wufeng02/"><img src="img/fengwu.jpg" class="img-responsive" alt="Image"  height="200"></a>
              <figcaption class="caption text-center">
                <a href="http://staff.ustc.edu.cn/~wufeng02/"><p><strong>吴锋</a></strong><br>
                      <small>中国科学技术大学</small>
                </p>
              </figcaption>
          </figure>
      </div>
      <!-- figure5 --> 
</div>
<!-- /.container -->

<h2 id="organizer">Workshop Chairs</h2>

<div id="wrapper">
      <div class="figure1">
          <figure class="thumbnail">
              <a href="http://sdcs.sysu.edu.cn/content/4883"><img src="img/chaoyu.jpg" class="img-responsive" alt="Image"  height="200"></a>
              <figcaption class="caption text-center">
                <a href="http://sdcs.sysu.edu.cn/content/4883"><p><strong>余超</a></strong><br>
                      <small>中山大学</small>
                </p>
              </figcaption>
          </figure>
      </div>
      <!-- figure1 --> 
  
      <div class="figure2">
          <figure class="thumbnail">
              <a href="http://www.lamda.nju.edu.cn/yuy/"><img src="img/yangyu.jpg" class="img-responsive" alt="Image" width="200" height="200"></a>
              <figcaption class="caption text-center">
                <a href="http://www.lamda.nju.edu.cn/yuy/"><p><strong>俞扬</a></strong><br>
                      <small>南京大学</small>
                </p>
              </figcaption>
          </figure>
      </div>
      <!-- figure2 -->
      <div class="figure3">
          <figure class="thumbnail">
              <a href="https://ai.nju.edu.cn/zhangzongzhang/"><img src="img/zzz.jpg" class="img-responsive" alt="Image" width="200" height="200"></a>
              <figcaption class="caption text-center">
                <a href="https://ai.nju.edu.cn/zhangzongzhang/"><p><strong>章宗长</a></strong><br>
                      <small>南京大学</small>
                </p>
              </figcaption>
          </figure>
      </div>
      <!-- figure3 -->

</div>
<!-- /.container -->


<!--TODO : this schedule will need to change to more accurately reflect what we are teaching -->
<h2 id="timetable">Overall Program</h2>
    <table class="table table-striped" width="500">
      <tr><td class="aligncenter" width="25%">9:00-9:40 (GMT+8)</td> <td class="aligncenter" width="25%"> Reinforcement Learning for Optimized Decision-making and Control of Intelligent Robots</td> <td class="aligncenter" width="25%">徐昕</td> <td class="aligncenter" width="25%">国防科技大学</td></tr>
      <tr><td class="aligncenter">9:40-10:20 (GMT+8)</td> <td class="aligncenter"> 实时格斗游戏中的人工智能方法 </td> <td class="aligncenter"> 赵东斌</td> </td> <td class="aligncenter"> 中国科学院 </td></tr>
      <tr><td class="aligncenter">10：20-10:50 (GMT+8)</td> <td class="aligncenter"> Reward Decomposition: Discover and Leverage Decomposable Structure in Deep Reinforcement Learning </td> <td class="aligncenter">赵丽 </td> <td class="aligncenter">微软亚洲研究院</td></tr>
      <tr><td class="aligncenter">10：50-11：20 (GMT+8)</td> <td class="aligncenter"> 路径积分强化学习及在控制系统中的应用 </td> <td class="aligncenter">郭宪 </td> <td class="aligncenter">南开大学</td></tr>
      <tr><td class="aligncenter" >11:20-11:50 (GMT+8)</td> <td class="aligncenter"> Model-based Reinforcement Learning </td> <td class="aligncenter">张俊格 </td> <td class="aligncenter"> 中国科学院</td></tr>
      <tr><td class="aligncenter">11:50-12:20 (GMT+8)</td> <td class="aligncenter"> 从模型复杂性角度看多智能体强化学习 </td> <td class="aligncenter">吴峰 </td> <td class="aligncenter"> 中国科学技术大学</td></tr>
    </table>
<hr/>

<h3>Talks</h3>
<p><strong>Reinforcement Learning for Optimized Decision-making and Control of Intelligent Robots</strong><br>
徐昕, 国防科技大学<br>
<strong>Time:</strong> 9:00-9:40 (GMT+8)<br>
<strong>Abstract:</strong> This talk will analyze the technical requirements and research challenges of intelligent robots under complex environments. To deal with the above challenges, the major models and algorithm frameworks of reinforcement learning (RL) will be introduced, together with some recent advances of feature representation and receding-horizon policy optimization in reinforcement learning algorithms.Then, some applications of RL in autonomous control and human-machine cooperative driving of intelligent vehicles will be introduced.Finally, the future research directions in related areas will also be discussed.   <br>

<p><strong>实时格斗游戏中的人工智能方法</strong><br>
赵东斌, 中国科学院<br>
<strong>Time:</strong> 9:40-10:20 (GMT+8)<br>
<strong>Abstract:</strong> 实时格斗游戏是一种典型的一对一的角色对抗游戏，通过在有限时间内有效打击对手获得胜利，是游戏人工智能领域的一个重要发展方向。近年来，以深度强化学习和统计前向规划为代表的人工智能方法在游戏中均取得了突破性进展。本报告主要介绍格斗游戏的特点，主要采用的人工智能方法，分析主流方法的优势及不足，重点介绍所提出的统计前向规划和强化学习对手建模相结合的方法（获得2020年格斗游戏竞赛冠军），并对相关领域的发展趋势进行展望。   <br>

<p><strong>Reward Decomposition: Discover and Leverage Decomposable Structure in Deep Reinforcement Learning</strong><br>
赵丽, 微软亚洲研究院<br>
<strong>Time:</strong> 10：20-10:50 (GMT+8)<br>
<strong>Abstract:</strong> Li Zhao is currently a Senior Researcher in Machine Learning Group, Microsoft Research Asia (MSRA). Her research interests mainly lie in deep learning and reinforcement learning, and their applications for text mining, recommendation, finance and games. She has co-organized the 3rd Asian Workshop on Reinforcement Learning (AWRL’18), and is one of the invited speakers for AWRL’19. She obtained her PhD degree majoring in Computer Science in July, 2016, from Tsinghua University, supervised by Professor Xiaoyan Zhu.  During her PhD studies, she has conducted research on sentiment extraction, text mining and weakly supervised learning. She published several research papers in top conferences, including NeurIPS, KDD, IJCAI, AAAI, EMNLP and CIKM.  <br>

<p><strong>路径积分强化学习及在控制系统中的应用</strong><br>
郭宪, 南开大学<br>
<strong>Time:</strong> 10：50-11：20 (GMT+8)<br>
<strong>Abstract:</strong> 近年来，强化学习技术在越来越多的领域取得突破性进展。然而，以马尔科夫决策过程为理论框架的强化学习技术往往只在动作离散的情景中表现很好，在动作连续的以微分方程为驱动的控制系统中表现不稳定。本报告介绍基于路径积分的强化学习算法，该算法的理论基础是哈密尔顿-雅克比-贝尔曼方程，针对该方程，通过引入恰当的假设，得到统计解，将微分方程的解转化为求解数学期望，最终用数据得到该期望的近似估计及当前的迭代最优策略。本报告首先介绍路径积分强化学习算法的基本原理，然后介绍课题组基于该方法在控制系统中的具体两个应用：（1）针对机器人路径跟踪控制问题，结合传统的非线性控制算法，实现比传统控制方法更好的智能路径跟踪方法；（2）针对高速飞行器的姿态控制问题，结合姿态控制问题本身的约束、pid控制器，提出高效鲁棒安全的姿态控制算法。针对这两个具体的控制问题，分享研究思路并提出强化学习在控制领域中的研究展望。 <br>

<p><strong>Model-based Reinforcement Learning</strong><br>
张俊格, 中国科学院<br>
<strong>Time:</strong> 11:20-11:50 (GMT+8)<br>
<strong>Abstract:</strong> DeepMind’s AlphaX (AlphaGo, AlphaZero, AlphaStar) have obtained great success in Go, Starcraft and all these systems consume huge computation resources. Few organizations can afford such huge cost to train an agent. Thus, data inefficiency becomes a major drawback for such advanced techniques. Model based reinforcement learning tries to capture the dynamics to greatly improve the data efficiency and is regarded as a promising framework to address such a limitation. This report will introduce the latest progress of model-based reinforcement learning and the three dilemmas faced by MBRL. Then we will discuss our work in this line of research. Finally, this report will summarize some possible research directions in the future. <br>

<p><strong>从模型复杂性角度看多智能体强化学习</strong><br>
吴峰, 中国科学技术大学<br>
<strong>Time:</strong> 11:50-12:20 (GMT+8)<br>
<strong>Abstract:</strong> 近年来，多智能体（深度）强化学习取得了大量重要的进展，但应用到现实问题中依然面临较大的挑战。这其中一部分来源于强化学习方法本身的复杂性，另一部分则源自多智能体分布式决策所带来的难度。例如单个智能体的MDP模型的求解复杂度是P，而多个智能体的Dec-POMDP模型的复杂度是NEXP（远大于P）。模型复杂度上的巨大差异，决定了多智能体分布式决策从根本上比单智能体的决策要难得多，强化学习作为一种基于学习的求解方法也无法幸免。当前，大多数强化算法在应用于多智能体决策时，都或多或少的隐含了若干的前提条件。这些条件在一定程度上可能弱化了问题的复杂度。当现实问题不满足这些（隐含）条件时，这些算法通常难以有满意的表现。本次报告将从模型复杂性的角度，对多智能体强化学习算法的设计进行探讨，以期能对多智能体强化学习算法的实际应用有所裨益。<br>


<h2 id="sponsor">Contact Person</h2>
<p>
    Dr. Chao Yu<br>
    Sun Yat-sen University, China<br>
    <strong>Email:</strong> yuchao3@mail.sysu.edu.cn<br>

</p>



<!--
</div>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>
  This workshop was made possible by professor Weinan Zhang.
</p>
-->

<!--<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=dQXgc8uBIK8rvujrNmLXRN3tKPsfMmPJUs36IZRUM7w&cl=ffffff&w=a"></script>-->
<br><br><br><br><br><br><br><br><br><br><br><br><br><br>


<br>
<p>
  This page was generated by <a href="https://pages.github.com">GitHub
  Pages</a> using the Architect theme
  by <a href="https://twitter.com/jasonlong">Jason Long</a>.
</p>

      </div>
    </div>
  </body>
</html>
